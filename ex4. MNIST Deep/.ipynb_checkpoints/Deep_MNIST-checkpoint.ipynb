{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Loading MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNISR_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNISR_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNISR_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNISR_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNISR_data\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set Size: 55000\n",
      "Validation Set Size: 5000\n",
      "Test Set Size: 10000\n"
     ]
    }
   ],
   "source": [
    "print('Train Set Size: {}' .format(len(mnist.train.images)))\n",
    "print('Validation Set Size: {}' .format(len(mnist.validation.images)))\n",
    "print('Test Set Size: {}' .format(len(mnist.test.images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Print an Random Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/ERCMfxEQv0fu1us9HchxSYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50e04d1a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randi = np.random.randint(len(mnist.train.images))\n",
    "plt.imshow(mnist.train.images[randi].reshape(28,28))\n",
    "for i in range(0,9):\n",
    "    if mnist.train.labels[randi][i]==1:\n",
    "        print('Label: {}' .format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight and Bias Initalisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_init(shape):\n",
    "    initial= tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_init(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution and Pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x,W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pooling_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conv > pool > conv > pool > dense > dropout > out \n",
    "\n",
    "def deepnn(x): \n",
    "    '''\n",
    "    x: input tensor with dimensions (n, 784)\n",
    "    \n",
    "    returns (y, keep_prob)\n",
    "    y: tensor of shape(n, 10)\n",
    "    keep_prob: scalar placeholder for the probability of dropout\n",
    "    '''\n",
    "    \n",
    "    # Reshape for convolution\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    \n",
    "    # First Convolutional Layer\n",
    "    W_conv1 = weight_init([5,5,1,32])\n",
    "    b_conv1 = bias_init([32])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    \n",
    "    # First Pooling Layer \n",
    "    h_pool1 = max_pooling_2x2(h_conv1)\n",
    "    \n",
    "    # Second Convolutional Layer\n",
    "    W_conv2 = weight_init([5,5,32,64])\n",
    "    b_conv2 = bias_init([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2)+b_conv2)\n",
    "    \n",
    "    # Second Pooling Layer \n",
    "    h_pool2 = max_pooling_2x2(h_conv2)\n",
    "    \n",
    "    \n",
    "    # First Fully Connected Layer - after 2 round of downsampling, our 28x28 image\n",
    "    # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "    W_fc1 = weight_init([7*7*64, 1024])\n",
    "    b_fc1 = bias_init([1024])\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    # Dropout \n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    \n",
    "    \n",
    "    # Second FC, Output \n",
    "    W_fc2 = weight_init([1024, 10])\n",
    "    b_fc2 = bias_init([10])\n",
    "    \n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) +  b_fc2\n",
    "    return y_conv, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "image_shape = 28\n",
    "input_size = image_shape * image_shape\n",
    "output_size =10\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 150\n",
    "\n",
    "epoch = 20\n",
    "epoch_size = 100\n",
    "n_steps = epoch * epoch_size \n",
    "\n",
    "# Create / Reset the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Input Images and Target Output Classes\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, output_size])\n",
    "\n",
    "y_conv, keep_prob = deepnn(x)\n",
    "\n",
    "# Note: tf.nn.softmax_cross_entropy_with_logits internally applies the softmax on the model's unnormalised model prediction and sums across all calsses \n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "\n",
    "# Train \n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "# Measurements \n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.arg_max(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for step in range(n_steps+1):\n",
    "    # Training\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    \n",
    "    # Print outs\n",
    "    if step%epoch_size==0:\n",
    "             print(\"Epoch: {} Accuracy: {:4.2f} \" .format(int(step/epoch_size),\n",
    "                accuracy.eval(feed_dict={x:batch[0], y_:batch[1], keep_prob: 1})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Predication Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Test Accuracy: {:4.2f}%' .format(100*accuracy.eval(feed_dict={x:mnist.test.images, y_:mnist.test.labels})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

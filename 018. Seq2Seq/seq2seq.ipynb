{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/guillaume-chevalier/seq2seq-signal-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "voc = 10\n",
    "n_steps = 14\n",
    "n_input = 2\n",
    "n_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(x.shape)\\nprint(y.shape)\\nprint(x[:, 0, :])\\nprint(y[:, 0])\\n#print(y[0])\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(batch_size):\n",
    "    x = np.random.randint(voc, size=[batch_size,n_steps, n_input])\n",
    "    y = np.flip(x, axis=1)\n",
    "    y = np.sum(y, axis=2)\n",
    "    y = y.reshape((batch_size, n_steps, 1))\n",
    "    \n",
    "    seq = np.empty((batch_size), dtype=np.int)\n",
    "    seq.fill(n_steps)\n",
    "    return x, y, seq\n",
    "\n",
    "x, y, seq = get_batch(100)\n",
    "\n",
    "#print(x[0])\n",
    "#print(y[0])\n",
    "\n",
    "print(seq)\n",
    "'''\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(x[:, 0, :])\n",
    "print(y[:, 0])\n",
    "#print(y[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 20\n",
    "layers_stacked_count = 2  # Number of stacked recurrent cells, on the neural depth axis. \n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "enc_inp = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
    "expect = tf.placeholder(tf.float32, [None, n_steps, 1])\n",
    "expect_length = tf.placeholder(tf.int32, [None])\n",
    "keep_prob = tf.placeholder(tf.float32, [])\n",
    "\n",
    "cells = [tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(n_hidden), output_keep_prob=keep_prob) for i in range(layers_stacked_count)]\n",
    "cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "\n",
    "encoded_outputs, encoded_states = tf.nn.dynamic_rnn(cell, enc_inp, dtype=tf.float32)\n",
    "\n",
    "helper = tf.contrib.seq2seq.TrainingHelper(expect, expect_length)\n",
    "\n",
    "de_cells = [tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(n_hidden), output_keep_prob=keep_prob) for i in range(layers_stacked_count)]\n",
    "de_cell = tf.contrib.rnn.MultiRNNCell(de_cells)\n",
    "\n",
    "decoder = tf.contrib.seq2seq.BasicDecoder(cell=de_cell, helper=helper, initial_state=encoded_states)\n",
    "\n",
    "decoder_outputs, final_decoder_state = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "\n",
    "decoder_logits = decoder_outputs.rnn_output\n",
    "\n",
    "h = tf.contrib.layers.fully_connected(decoder_logits, n_output)\n",
    "\n",
    "diff = tf.squared_difference(h, expect)\n",
    "batch_loss = tf.reduce_sum(diff, axis=1)\n",
    "loss = tf.reduce_mean(batch_loss)\n",
    "\n",
    "optimiser = tf.train.AdamOptimizer(1e-3)\n",
    "training_op = optimiser.minimize(loss)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280.096\n",
      "219.746\n",
      "221.117\n",
      "115.689\n",
      "53.676\n",
      "37.8953\n",
      "24.4736\n",
      "19.1247\n",
      "19.1786\n",
      "14.2717\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "init_op.run()\n",
    "\n",
    "for e in range(10):\n",
    "    for i in range(100):\n",
    "        batch_x, batch_y ,seq = get_batch(50)\n",
    "        training_op.run(feed_dict={enc_inp:batch_x, expect: batch_y, expect_length:seq, keep_prob:0.5})\n",
    "        \n",
    "    print(loss.eval(feed_dict={enc_inp:batch_x, expect: batch_y, expect_length:seq, keep_prob:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15]\n",
      " [10]\n",
      " [ 5]\n",
      " [17]\n",
      " [15]\n",
      " [ 9]\n",
      " [ 8]\n",
      " [16]\n",
      " [ 7]\n",
      " [ 4]\n",
      " [ 8]\n",
      " [ 7]\n",
      " [ 6]\n",
      " [ 8]]\n",
      "---------\n",
      "[[ 13.11734104]\n",
      " [  9.93261909]\n",
      " [  4.59088039]\n",
      " [ 13.38347816]\n",
      " [ 13.1373806 ]\n",
      " [  8.84623623]\n",
      " [  7.51879263]\n",
      " [ 13.3497324 ]\n",
      " [  6.21972895]\n",
      " [  3.92029834]\n",
      " [  7.83621931]\n",
      " [  6.41021967]\n",
      " [  5.42207432]\n",
      " [  7.76618719]]\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y, seq = get_batch(2)\n",
    "print(test_y[0])\n",
    "print('---------')\n",
    "feed_dict = {enc_inp:test_x, expect:test_y, expect_length:seq, keep_prob:1}\n",
    "pred = h.eval(feed_dict=feed_dict)\n",
    "\n",
    "print(pred[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 55.52490997]\n",
      "[ 45.62505341]\n",
      "[ 50.34844208]\n",
      "[ 49.02774429]\n",
      "[ 45.09157562]\n",
      "[ 53.64335632]\n",
      "[ 42.15190125]\n",
      "[ 45.09565735]\n",
      "[ 40.51711655]\n",
      "[ 39.62434006]\n",
      "[ 42.93576813]\n",
      "[ 36.71058655]\n",
      "[ 30.19380569]\n",
      "[ 30.20914459]\n",
      "[ 30.45394897]\n",
      "[ 28.07727051]\n",
      "[ 26.55237579]\n",
      "[ 24.03799057]\n",
      "[ 23.85711479]\n",
      "[ 26.63663101]\n"
     ]
    }
   ],
   "source": [
    "for e in range(20):\n",
    "    for i in range(100):\n",
    "        batch_x, batch_y = get_batch(50)\n",
    "        feed_dict = {enc_inp[t]:batch_x[t] for t in range(len(enc_inp))}\n",
    "        feed_dict.update({expect[t]: batch_y[t] for t in range(len(expect))})\n",
    "        training_op.run(feed_dict=feed_dict)\n",
    "        \n",
    "    print(loss.eval(feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
